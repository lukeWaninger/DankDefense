{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.365Z"
    },
    "code_folding": [
     27,
     42,
     49,
     56,
     59,
     62,
     74
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from scipy.sparse import hstack \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "def nanp(df, show_zero=False):\n",
    "    cols = df.columns\n",
    "    d, p = len(df), []\n",
    "\n",
    "    for i, col in enumerate(cols):\n",
    "        a = sum(pd.isnull(df[col]))\n",
    "        p.append([col, df[col].dtype, np.round(a/d*100, 1)])\n",
    "    \n",
    "    p = pd.DataFrame(p, columns=['Variable', 'DataType', 'PercentNA'])\n",
    "    \n",
    "    if not show_zero:\n",
    "        return p.loc[p['PercentNA'] > 0].sort_values(by='PercentNA', ascending=False)\n",
    "    else:\n",
    "        return p.sort_values(by='PercentNA', ascending=False)\n",
    "    \n",
    "def isfloat(x):\n",
    "    try:\n",
    "        float(x)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def isint(x):\n",
    "    try:\n",
    "        int(x)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def dfcols():\n",
    "    [print(c) for c in sorted(df.columns)]\n",
    "    \n",
    "def printcats(c):\n",
    "    df[c] = df[c].apply(lambda x: str(x).lower() if not pd.isnull(x) else np.nan)\n",
    "    \n",
    "    df.loc[\n",
    "        (df.loc[:, c] == 'unknown') |\n",
    "        (df.loc[:, c] == 'unspecified') |\n",
    "        df.loc[:, c].isnull(), c\n",
    "    ] = np.nan\n",
    "    \n",
    "    un = df[c].unique()\n",
    "    if len(un) < 20:\n",
    "        print(c, len(c), ':', un)\n",
    "    else:\n",
    "        print(c, len(c), ':', ', '.join([str(x) for x in un[:5]]) + ', ...')\n",
    "\n",
    "def cateval(df, c):\n",
    "    print('percent na: ', df[c].isnull().mean())\n",
    "    t = pd.crosstab(df[c], df.HasDetections, normalize='index').sort_values(c)\n",
    "    t['total_count'] = df[c].value_counts()\n",
    "    t['normalized'] = t.total_count/t.total_count.sum()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.369Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('traing_sample.csv')\n",
    "\n",
    "#df.read_csv('train.csv').sample(int(10e5)).to_csv('traing_sample.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.372Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "binary_cols = [\n",
    "    'IsBeta',\n",
    "    'IsSxsPassiveMode',\n",
    "    'HasTpm',\n",
    "    'IsProtected',\n",
    "    'AutoSampleOptIn',\n",
    "    'SMode',\n",
    "    'Firewall',\n",
    "    'UacLuaenable',\n",
    "    'Census_HasOpticalDiskDrive',\n",
    "    'Census_IsPortableOperatingSystem',\n",
    "    'Census_IsFlightingInternal',\n",
    "    'Census_IsFlightsDisabled',\n",
    "    'Census_IsSecureBootEnabled',\n",
    "    'Census_IsWIMBootEnabled',\n",
    "    'Census_IsVirtualDevice',\n",
    "    'Census_IsTouchEnabled',\n",
    "    'Census_IsPenCapable',\n",
    "    'Census_IsAlwaysOnAlwaysConnectedCapable',\n",
    "    'Wdft_IsGamer'\n",
    "]\n",
    "\n",
    "for c in tqdm(binary_cols):\n",
    "    df[c] = df[c].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.375Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "    'ProductName',\n",
    "    'AVProductStatesIdentifier',\n",
    "    'CountryIdentifier',\n",
    "    'CityIdentifier',\n",
    "    'OrganizationIdentifier',\n",
    "    'GeoNameIdentifier',\n",
    "    'LocaleEnglishNameIdentifier',\n",
    "    'Platform',\n",
    "    'Processor',\n",
    "    'OsSuite',\n",
    "    'OsBuildLab',\n",
    "    'SkuEdition',\n",
    "    'IeVerIdentifier',\n",
    "    'SmartScreen',\n",
    "    'Census_MDC2FormFactor',\n",
    "    'Census_DeviceFamily',\n",
    "    'Census_OEMNameIdentifier',\n",
    "    'Census_OEMModelIdentifier',\n",
    "    'Census_ProcessorManufacturerIdentifier',\n",
    "    'Census_ProcessorModelIdentifier',\n",
    "    'Census_PrimaryDiskTypeName',\n",
    "    'Census_ChassisTypeName',\n",
    "    'Census_PowerPlatformRoleName',\n",
    "    'Census_InternalBatteryType',\n",
    "    'Census_OSArchitecture',\n",
    "    'Census_OSBranch',\n",
    "    'Census_OSEdition',\n",
    "    'Census_OSSkuName',\n",
    "    'Census_OSInstallTypeName',\n",
    "    'Census_OSInstallLanguageIdentifier',\n",
    "    'Census_OSUILocaleIdentifier',\n",
    "    'Census_OSWUAutoUpdateOptionsName',\n",
    "    'Census_GenuineStateName',\n",
    "    'Census_ActivationChannel',\n",
    "    'Census_FlightRing',\n",
    "    'Census_FirmwareManufacturerIdentifier',\n",
    "    'Census_FirmwareVersionIdentifier',\n",
    "]\n",
    "\n",
    "for c in tqdm(categorical_cols):\n",
    "    if c not in df.columns:\n",
    "        print(c)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        df[c] = df[c].astype('object')\n",
    "    except:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.379Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    'Census_ThresholdOptIn',\n",
    "    'Census_InternalBatteryNumberOfCharges',\n",
    "    'Census_TotalPhysicalRAM',\n",
    "    'Census_OSBuildNumber',\n",
    "    'Census_PrimaryDiskTotalCapacity',\n",
    "    'Census_SystemVolumeTotalCapacity',\n",
    "    'Census_ProcessorCoreCount',\n",
    "    'Census_InternalPrimaryDiagonalDisplaySizeInInches',\n",
    "    'Census_InternalPrimaryDisplayResolutionHorizontal',\n",
    "    'Census_InternalPrimaryDisplayResolutionVertical',\n",
    "    'AVProductsEnabled',\n",
    "    'AVProductsInstalled',\n",
    "    'RtpStateBitfield',\n",
    "]\n",
    "\n",
    "for c in tqdm(numeric_cols):\n",
    "    df[c] = pd.to_numeric(df[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.382Z"
    }
   },
   "outputs": [],
   "source": [
    "drop = [\n",
    "    'PuaMode',\n",
    "    'Census_ProcessorClass',\n",
    "    'DefaultBrowsersIdentifier',\n",
    "    'Wdft_RegionIdentifier',\n",
    "]\n",
    "df = df.drop(columns=drop, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Extract major and minor versions from hierarchical version strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.386Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['MajorEngineVersion'] = df.EngineVersion.apply(lambda x: int(x.split('.')[2]))\n",
    "df['MinorEngineVersion'] = df.EngineVersion.apply(lambda x: int(x.split('.')[3]))\n",
    "df['EngineVersion'] = df.EngineVersion.apply(lambda x: float('.'.join(x.split('.')[2:])))\n",
    "\n",
    "numeric_cols.append('MajorEngineVersion')\n",
    "numeric_cols.append('MinorEngineVersion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.391Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['MajorAppVersion'] = df.AppVersion.apply(lambda x: int(x.split('.')[1]))\n",
    "\n",
    "numeric_cols.append('MajorAppVersion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.395Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['MinorAppVersion'] = df.AppVersion.apply(lambda x: x.split('.')[2])\n",
    "\n",
    "mlen = np.max([len(v) for v in df['MinorAppVersion']])\n",
    "df['MinorAppVersion'] = df.MinorAppVersion.apply(lambda x: int(f'1{x.zfill(mlen)}'))\n",
    "\n",
    "numeric_cols.append('MinorAppVersion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.399Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['FinestAppVersion'] = df.AppVersion.apply(lambda x: x.split('.')[3])\n",
    "\n",
    "mlen = np.max([len(v) for v in df['FinestAppVersion']])\n",
    "df['FinestAppVersion'] = df.FinestAppVersion.apply(lambda x: int(f'1{x.zfill(mlen)}'))\n",
    "\n",
    "numeric_cols.append('FinestAppVersion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.403Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['AppVersion'] = [\n",
    "    float(f'{t[0]}.{t[1]}{t[2]}') for t in df[\n",
    "        ['MajorAppVersion', 'MinorAppVersion', 'FinestAppVersion']\n",
    "    ].itertuples()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['MajorAvSigVersion'] = df.AvSigVersion.apply(lambda x: int(x.split('.')[1]))\n",
    "df['MinorAvSigVersion'] = df.AvSigVersion.apply(lambda x: int(x.split('.')[2]))\n",
    "df['AvSigVersion'] = df.AvSigVersion.apply(lambda x: float('.'.join(x.split('.')[1:3])))\n",
    "\n",
    "numeric_cols.append('MajorAvSigVersion')\n",
    "numeric_cols.append('MinorAvSigVersion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.409Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['Census_MajorOSVersion'] = df.Census_OSVersion.apply(lambda x: int(x.split('.')[2]))\n",
    "df['Census_MinorOSVersion'] = df.Census_OSVersion.apply(lambda x: int(x.split('.')[3]))\n",
    "df['Census_OSVersion'] = df.Census_OSVersion.apply(lambda x: float('.'.join(x.split('.')[2:])))\n",
    "\n",
    "numeric_cols.append('Census_MajorOSVersion')\n",
    "numeric_cols.append('Census_MinorOSVersion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T02:56:35.176163Z",
     "start_time": "2019-01-09T02:56:35.141669Z"
    }
   },
   "source": [
    "### Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.412Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for c in categorical_cols:\n",
    "    printcats(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `Identifiers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.417Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "identifiers = [\n",
    "    'Census_ProcessorModelIdentifier',\n",
    "    'Census_FirmwareManufacturerIdentifier',\n",
    "    'Census_FirmwareVersionIdentifier',\n",
    "    'Census_OEMNameIdentifier',\n",
    "    'Census_OEMModelIdentifier',\n",
    "    'Census_OSInstallLanguageIdentifier',\n",
    "    'IeVerIdentifier',\n",
    "    'Census_ProcessorManufacturerIdentifier',\n",
    "    'Census_ProcessorModelIdentifier',\n",
    "    'AVProductStatesIdentifier',\n",
    "    'OrganizationIdentifier',\n",
    "    'CityIdentifier'\n",
    "]\n",
    "for c in identifiers:\n",
    "    df[c] = df[c].fillna('missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.420Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nanp(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `Census_FlightRing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.424Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.Census_FlightRing = df.Census_FlightRing.fillna('missing')\n",
    "cateval(df, 'Census_FlightRing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `Census_PowerPlatformRoleName`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.430Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.Census_PowerPlatformRoleName = df.Census_PowerPlatformRoleName.fillna('missing')\n",
    "cateval(df, 'Census_PowerPlatformRoleName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `Census_OSWUAutoUpdateOptionsName`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.434Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.Census_OSWUAutoUpdateOptionsName = df.Census_OSWUAutoUpdateOptionsName.fillna('missing')\n",
    "cateval(df, 'Census_OSWUAutoUpdateOptionsName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `Census_GenuineStateName`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.438Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.Census_GenuineStateName = df.Census_GenuineStateName.fillna('missing')\n",
    "cateval(df, 'Census_GenuineStateName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `SmartScreen`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Fix the ascii characters in smart screen. Why did these report as 'start of heading' and 'start of text'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Could possible convert to an ordinal variable using a bit of logic where 0 is least secure and n is most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.443Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.loc[\n",
    "    (df.SmartScreen == '&#x01;') |\n",
    "    (df.SmartScreen == '&#x02;'), \n",
    "    'SmartScreen'\n",
    "] = 'invalid'\n",
    "df.SmartScreen = df.SmartScreen.fillna('missing')\n",
    "\n",
    "cateval(df, 'SmartScreen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `Census_InternalBatteryType`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I first replace any non-alphanumeric characters and then group the outlying minor battery types into one category - 'others'.\n",
    "\n",
    "I want to take a closer look at https://batteryuniversity.com/learn/article/types_of_battery_cells and estimate a device lifespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.448Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.Census_InternalBatteryType = df.Census_InternalBatteryType.progress_apply(\n",
    "    lambda x: re.sub('[^0-9a-zA-Z]+', '_', str(x).replace('#', 'pnd')) if pd.notna(x) else np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.451Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "others = df.Census_InternalBatteryType.value_counts()\n",
    "others = others[others < 184].index.tolist()\n",
    "\n",
    "mask = [c in others for c in df.Census_InternalBatteryType]\n",
    "df.loc[mask, 'Census_InternalBatteryType'] = 'other'\n",
    "\n",
    "df.loc[df.Census_InternalBatteryType.isnull(), 'Census_InternalBatteryType'] = 'missing'\n",
    "\n",
    "cateval(df, 'Census_InternalBatteryType')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Census_OSEdition` and `Census_OSSkuName`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two features express the same information but differ on occasion. I first remove any non-alphanumeric characters from both features. Next, I check to see if they match by seeing if any substring of length four exists in the other. I do it like this because many are the same but with different orderings (datacenterserver and server_datacenter for example).\n",
    "\n",
    "I also extract the OS versions that have reduced media applications by default.\n",
    "https://www.howtogeek.com/322112/what-is-an-n-or-kn-edition-of-windows/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.455Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['Census_OSSkuName'] = [re.sub(r'[^a-zA-Z]+', '', s) for s in df.Census_OSSkuName]\n",
    "df['Census_OSEdition'] = [re.sub(r'[^a-zA-Z]+', '', s) for s in df.Census_OSEdition]\n",
    "\n",
    "# extract the media reduced OS versions\n",
    "OS_Reduced_Media = [\n",
    "    'professionaln',\n",
    "    'coren',\n",
    "    'enterprisesn',\n",
    "    'enterprisen',\n",
    "    'professionalworkstationn',\n",
    "    'cloudn',\n",
    "    'educationn',\n",
    "    'professionaleducationn'\n",
    "]\n",
    "\n",
    "mask = [\n",
    "    c[0] in OS_Reduced_Media or c[1] in OS_Reduced_Media \n",
    "    for c in df[['Census_OSSkuName', 'Census_OSEdition']].itertuples() \n",
    "]\n",
    "df['OS_Reduced_Media'] = mask\n",
    "\n",
    "for c in OS_Reduced_Media:\n",
    "    df.loc[df.Census_OSSkuName == c, 'Census_OSSkuName'] = c[:-1]\n",
    "    df.loc[df.Census_OSEdition == c, 'Census_OSEdition'] = c[:-1]\n",
    "\n",
    "# replace the obvious typo\n",
    "df.loc[\n",
    "    (df.Census_OSEdition == 'enterprises') |\n",
    "    (df.Census_OSSkuName == 'enterprises'),\n",
    "    ['Census_OSEdition', 'Census_OSSkuName']\n",
    "] = 'enterprise'\n",
    "\n",
    "\n",
    "# There are only one of these in the entire dataset\n",
    "df.loc[\n",
    "    (df.Census_OSEdition == 'professionalsinglelanguage') |\n",
    "    (df.Census_OSSkuName == 'professionalsinglelanguage'),\n",
    "    ['Census_OSEdition', 'Census_OSSkuName']\n",
    "] = 'professional'\n",
    "\n",
    "df.loc[\n",
    "    (df.Census_OSEdition == 'professionalcountryspecific') |\n",
    "    (df.Census_OSSkuName == 'professionalcountryspecific'),\n",
    "    ['Census_OSEdition', 'Census_OSSkuName']\n",
    "] = 'professional'\n",
    "\n",
    "df.loc[\n",
    "    (df.Census_OSEdition == 'professionalcountryspecific') |\n",
    "    (df.Census_OSSkuName == 'professionalcountryspecific'),\n",
    "    ['Census_OSEdition', 'Census_OSSkuName']\n",
    "] = 'professional'\n",
    "\n",
    "# look for substring matches\n",
    "step, subsets = 4, {}\n",
    "for s in df.Census_OSEdition.unique():\n",
    "    subsets[s] = {s[i:i+step] for i in range(len(s)-step+1)}\n",
    "\n",
    "df['Census_OSEdSkuMatch'] = [\n",
    "    any([\n",
    "        x in z for x in subsets[y]\n",
    "    ])\n",
    "    for y, z in zip(df.Census_OSEdition, df.Census_OSSkuName)\n",
    "]\n",
    "t = df[['Census_OSEdition', 'Census_OSSkuName', 'Census_OSEdSkuMatch', 'OS_Reduced_Media']]\n",
    "\n",
    "print('no match')\n",
    "t.loc[[not b for b in t.duplicated()] & ~t.Census_OSEdSkuMatch]\n",
    "\n",
    "print()\n",
    "print('matches')\n",
    "t.loc[[not b for b in t.duplicated()] & t.Census_OSEdSkuMatch].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are very few non-matching columns and I'm assuming one of them was entered incorrectly. To fix it, I calculate the probabilities of either and choose one at random. I drop the second column after making updates to the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.463Z"
    }
   },
   "outputs": [],
   "source": [
    "(df.Census_OSEdition.isnull() | df.Census_OSSkuName.isnull()).mean()\n",
    "df.Census_OSEdSkuMatch.mean()\n",
    "osed_props = df.Census_OSEdition.value_counts(normalize=True)\n",
    "ossku_props = df.Census_OSSkuName.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.466Z"
    }
   },
   "outputs": [],
   "source": [
    "for ix, row in df.iloc[\n",
    "    t.loc[[not b for b in t.duplicated()] & ~t.Census_OSEdSkuMatch].index][\n",
    "        ['Census_OSEdition', 'Census_OSSkuName', 'Census_OSEdSkuMatch']].iterrows():\n",
    "    a, b = osed_props[row.Census_OSEdition], ossku_props[row.Census_OSSkuName]\n",
    "    p = b/(a+b)\n",
    "    choice = np.random.binomial(1, p, 1)\n",
    "    if choice == 1:\n",
    "        #print(p, 1, row.Census_OSSkuName)\n",
    "        df.loc[ix, 'Census_OSEdition'] = row.Census_OSSkuName\n",
    "    else:\n",
    "        #print(p, 0, row.Census_OSEdition)\n",
    "        df.loc[ix, 'Census_OSEdition'] = row.Census_OSEdition\n",
    "        \n",
    "df.drop(columns=['Census_OSSkuName'], inplace=True)\n",
    "categorical_cols.remove('Census_OSSkuName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.469Z"
    }
   },
   "outputs": [],
   "source": [
    "cateval(df, 'Census_OSEdition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `OSPlatformSubRelease` and `Census_OSBranch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.474Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def branch_ver(x):\n",
    "    m = re.search(r'[0-9_]', x)\n",
    "    idx = m.span()[0] if m is not None else len(x)\n",
    "    return x[:idx]\n",
    "\n",
    "t = df[['Census_OSBranch', 'OsPlatformSubRelease']].copy()\n",
    "t.columns = ['branch', 'subrel']\n",
    "\n",
    "t.branch = t.branch.apply(lambda x: x.replace('release', ''))\n",
    "t['branch_ver'] = [branch_ver(x) for x in t.branch]\n",
    "t['subrel_ver'] = [branch_ver(x) for x in t.subrel]\n",
    "\n",
    "t['subrel_ver_num'] = [re.sub(r'[^0-9.]', '', c) for c in t.subrel]\n",
    "t['subrel_ver_num'] = [\n",
    "    np.round(float(x), 1) if isfloat(x) else np.nan for x in t.subrel_ver_num\n",
    "]\n",
    "\n",
    "t['branch_release_num'] = [re.sub(r'[^0-9.]', '', c) for c in t.branch] \n",
    "t['branch_release_num'] = [\n",
    "    np.round(float(x[0]), 1) if len(x) > 0 and isfloat(x[0]) else np.nan for x in t.branch_release_num\n",
    "]\n",
    "\n",
    "t['is_svc_release'] = ['svc' in c for c in t.branch]\n",
    "t['is_escrow_release'] = ['escrow' in c for c in t.branch]\n",
    "t['is_sec_release'] = ['sec' in c for c in t.branch]\n",
    "t['is_st1_release'] = ['st1' in c for c in t.branch]\n",
    "t['is_prerelease'] = ['pre' in c for c in t.branch]\n",
    "t['is_special_release'] = [\n",
    "    any([y in c for y in ['flt', 'sigma', 'edge']]) \n",
    "    for c in t.branch\n",
    "]\n",
    "\n",
    "t.loc[t.subrel_ver == 'prers', 'is_prerelease'] = True\n",
    "t.loc[t.subrel_ver == 'prers', 'subrel_ver'] = 'rs'\n",
    "\n",
    "t.loc[['win' in c for c in t.branch_ver], 'branch_ver'] = 'win'\n",
    "\n",
    "t.loc[t.branch_release_num.isnull(), 'branch_release_num'] = 0\n",
    "\n",
    "t.drop(columns=['branch', 'subrel'], inplace=True)\n",
    "t.head()\n",
    "t.branch_ver.value_counts()\n",
    "t.subrel_ver.value_counts()\n",
    "\n",
    "for c in t.columns:\n",
    "    df[c] = t[c]\n",
    "\n",
    "categorical_cols += ['branch_ver', 'subrel_ver']\n",
    "numeric_cols += ['subrel_ver_num', 'branch_release_num']\n",
    "binary_cols += ['is_svc_release', 'is_escrow_release', 'is_sec_release', 'is_st1_release', 'is_prerelease', 'is_special_release']\n",
    "\n",
    "df = df.drop(columns=['Census_OSBranch', 'OsPlatformSubRelease'])\n",
    "categorical_cols.remove('Census_OSBranch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### `Census_MDC2_FormFactor` and `Census_ChassisTypeName`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "https://www.dmtf.org/sites/default/files/standards/documents/DSP0134_3.2.0.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.478Z"
    },
    "code_folding": [
     2
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t = df[['Census_MDC2FormFactor', 'Census_ChassisTypeName']]\n",
    "\n",
    "ff_int = {\n",
    "    'other':1,\n",
    "    'unkown':2,\n",
    "    'desktop':3,\n",
    "    'lowprofiledesktop':4,\n",
    "    'pizzabox':5,\n",
    "    'minitower':6,\n",
    "    'tower':7,\n",
    "    'portable':8,\n",
    "    'laptop':9,\n",
    "    'notebook':10,\n",
    "    'handheld':11,\n",
    "    'dockingstation':12,\n",
    "    'allinone':13,\n",
    "    'subnotebook':14,\n",
    "    'spacesaving':15,\n",
    "    'lunchbox':16,\n",
    "    'mainserverchassis':17,\n",
    "    'expansionchassis':19,\n",
    "    'subchassis':20,\n",
    "    'busexpansionchassis':21,\n",
    "    'peripheralchassis':22,\n",
    "    'raidchassis':23,\n",
    "    'rackmountchassis':24,\n",
    "    'sealedcasepc':25,\n",
    "    'multisystemchassis':26,\n",
    "    'compactpci':27,\n",
    "    'advancedtca':28,\n",
    "    'blade':29,\n",
    "    'bladeenclosure':30,\n",
    "    'tablet':31,\n",
    "    'convertible':32,\n",
    "    'detachable':33,\n",
    "    'iotgateway':34,\n",
    "    'embeddedpc':35,\n",
    "    'minipc':36,\n",
    "    'stickpc':37\n",
    "}\n",
    "int_ff = { v:k for k, v in ff_int.items() }\n",
    "\n",
    "mask = [isint(x) and x in int_ff.keys() for x in df.Census_MDC2FormFactor]\n",
    "df.loc[mask, 'Census_MDC2FormFactor'] = [int_ff[int(x)] for x in df.loc[mask, 'Census_MDC2FormFactor']]\n",
    "\n",
    "mask = [isint(x) and x in int_ff.keys() for x in df.Census_ChassisTypeName]\n",
    "df.loc[mask, 'Census_ChassisTypeName'] = [int_ff[int(x)] for x in df.loc[mask, 'Census_ChassisTypeName']]\n",
    "\n",
    "df.loc[[c not in ff_int.keys() for c in df.Census_MDC2FormFactor], 'Census_MDC2FormFactor'] = 'invalid'\n",
    "df.loc[[c not in ff_int.keys() for c in df.Census_ChassisTypeName], 'Census_ChassisTypeName'] = 'invalid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.481Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "step, subsets = 5, {}\n",
    "for s in df.Census_MDC2FormFactor.unique():\n",
    "    subsets[s] = {s[i:i+step] for i in range(len(s)-step+1)}\n",
    "\n",
    "df['Census_FFMatch'] = [\n",
    "    any([\n",
    "        x in str(z) for x in subsets[y]\n",
    "    ])\n",
    "    for y, z in zip(df.Census_MDC2FormFactor, df.Census_ChassisTypeName)\n",
    "]\n",
    "t = df[['Census_MDC2FormFactor', 'Census_ChassisTypeName', 'Census_FFMatch']]\n",
    "\n",
    "print('no match')\n",
    "t.loc[[not b for b in t.duplicated()] & ~t.Census_FFMatch].head(10)\n",
    "\n",
    "print()\n",
    "print('matches')\n",
    "t.loc[[not b for b in t.duplicated()] & t.Census_FFMatch].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.484Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cateval(df, 'Census_MDC2FormFactor')\n",
    "cateval(df, 'Census_ChassisTypeName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `OsVer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OsVer has an ordering we can take advantage of: https://docs.microsoft.com/en-us/windows/desktop/sysinfo/operating-system-version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.489Z"
    }
   },
   "outputs": [],
   "source": [
    "os_versions = {\n",
    "    k:v for v, k in enumerate(sorted(df.OsVer.unique(), reverse=True))\n",
    "}\n",
    "for k, v in os_versions.items():\n",
    "    df.loc[df['OsVer']==k, 'OsVer'] = v\n",
    "    \n",
    "numeric_cols.append('OsVer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.491Z"
    }
   },
   "outputs": [],
   "source": [
    "df.OsVer.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Census_PrimaryDiskType`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.495Z"
    }
   },
   "outputs": [],
   "source": [
    "disk_types = {\n",
    "    'hdd':0,\n",
    "    'ssd':1\n",
    "}\n",
    "for k, v in disk_types.items():\n",
    "    df.loc[df.Census_PrimaryDiskTypeName == k, 'Census_PrimaryDiskTypeName'] = v\n",
    "    \n",
    "df.Census_PrimaryDiskTypeName = pd.to_numeric(df.Census_PrimaryDiskTypeName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.499Z"
    }
   },
   "outputs": [],
   "source": [
    "cateval(df, 'Census_PrimaryDiskTypeName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.501Z"
    }
   },
   "outputs": [],
   "source": [
    "t = df.corr().Census_PrimaryDiskTypeName.sort_values()\n",
    "t.loc[np.abs(t) > .1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.504Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ = df.drop(columns=['MachineIdentifier'], errors='ignore').copy()\n",
    "df_ = df_.dropna(subset=list(set(df_.columns)-{'Census_PrimaryDiskTypeName'}))\n",
    "\n",
    "categorical_cols_ = list(set(categorical_cols) - {'Census_PrimaryDiskTypeName'})\n",
    "for c in tqdm(categorical_cols_):\n",
    "    df_[c] = df_[c].astype(str)\n",
    "\n",
    "mask = df_.Census_PrimaryDiskTypeName.isnull()\n",
    "\n",
    "x_train = df_.loc[~mask]\n",
    "x_pre = df_.loc[mask]\n",
    "x_pre_idx = x_pre.index.tolist()\n",
    "\n",
    "y_train = x_train.Census_PrimaryDiskTypeName\n",
    "\n",
    "x_train = x_train.drop(columns=['Census_PrimaryDiskTypeName'])\n",
    "x_pre = x_pre.drop(columns=['Census_PrimaryDiskTypeName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.507Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "laEncs = {}\n",
    "for c in tqdm(categorical_cols_):\n",
    "    enc = LabelEncoder().fit(df_[c])\n",
    "    \n",
    "    x_train[c] = enc.transform(x_train[c])\n",
    "    x_pre[c] = enc.transform(x_pre[c])\n",
    "    \n",
    "    laEncs[c] = enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.510Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name = 'census_primary_disk_type.model'\n",
    "\n",
    "if os.path.exists(name):\n",
    "    with open(name, 'rb') as f:\n",
    "        cv = pickle.loads(f.read())\n",
    "else:\n",
    "    # setup the cross-validation scheme\n",
    "    params = {\n",
    "        'learning_rate':     [0.2],  # np.linspace(0.1, .3, 5),\n",
    "        'n_estimators':      [1500], # [100, 1000, 1500, 2000, 3000],\n",
    "        'max_depth':         [10],   # range(5, 15, 5),\n",
    "        'min_samples_split': [600],  # range(200, 1000, 200),\n",
    "        'min_samples_leaf':  [10],   # range(10, 50, 8)\n",
    "    }\n",
    "    \n",
    "    cv = GridSearchCV(\n",
    "        GradientBoostingClassifier(max_features='sqrt'), \n",
    "        params, \n",
    "        cv=3, \n",
    "        n_jobs=-1, \n",
    "        verbose=10,\n",
    "        refit=True\n",
    "    )\n",
    "\n",
    "    # fit\n",
    "    cv = cv.fit(x_train, y_train)\n",
    "    \n",
    "    # save\n",
    "    with open(name, 'wb') as f:\n",
    "        f.write(pickle.dumps(cv))\n",
    "\n",
    "print(cv.best_params_)\n",
    "print(cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.513Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pre = cv.predict(x_pre)\n",
    "df.loc[x_pre_idx, 'Census_PrimaryDiskTypeName'] = y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.515Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df.Census_PrimaryDiskTypeName.isnull(), 'Census_PrimaryDiskTypeName'] = \n",
    "\n",
    "cateval(df, 'Census_PrimaryDiskTypeName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `RtpStateBitfield`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.520Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df.RtpStateBitfield.isnull(), 'RtpStateBitfield'] = 34\n",
    "cateval(df, 'RtpStateBitfield')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.522Z"
    }
   },
   "outputs": [],
   "source": [
    "df.RtpStateBitfield = [\n",
    "    str(bin(int(float(c))))[2:].zfill(4) if str(c) != 'nan' else np.nan \n",
    "    for c in df.RtpStateBitfield\n",
    "]\n",
    "\n",
    "df.RtpStateBitfield.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.527Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    cname = f'RtpStateBitfield_{i}'\n",
    "    df[cname] = df.RtpStateBitfield.apply(\n",
    "        lambda x: bool(x[4-i]) if str(x) != 'nan' else np.nan\n",
    "    )\n",
    "    binary_cols.append(cname)\n",
    "\n",
    "df = df.drop(columns=['RtpStateBitfield'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.529Z"
    }
   },
   "outputs": [],
   "source": [
    "ex_set = [\n",
    "    'Census_InternalBatteryType',\n",
    "    'Census_ThresholdOptIn',\n",
    "    'SmartScreen',\n",
    "    'OrganizationIdentifier',\n",
    "    'MachineIdentifier'\n",
    "]\n",
    "\n",
    "#list(set(t.loc[t.DataType == 'object'].Variable.tolist()) - set(ex_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Columns - fill with logistic regression\n",
    "https://www.sciencedirect.com/science/article/pii/S0166218X11000503"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure I have all the features subsetted into _categorical_, _binary_, or _numeric_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.533Z"
    }
   },
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    if not (c in categorical_cols or c in binary_cols or c in numeric_cols):\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.536Z"
    }
   },
   "outputs": [],
   "source": [
    "crr = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.540Z"
    }
   },
   "outputs": [],
   "source": [
    "crr.Census_PrimaryDiskTypeName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.546Z"
    }
   },
   "outputs": [],
   "source": [
    "encoders = {}\n",
    "for c in categorical_cols[:1]:\n",
    "    f = [[fi, i] for i, fi in enumerate(df[c].value_counts().index)]\n",
    "    encoders[c] = OneHotEncoder(handle_unknown='ignore').fit(df[c])\n",
    "    print(encoders[c].transform(df[c].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.551Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "in_set = [c for c in df.columns if c not in ex_set]\n",
    "\n",
    "x = df.loc[~mask, in_set].dropna(how='any')\n",
    "y = x.Census_PrimaryDiskTypeName.values\n",
    "\n",
    "x = x.drop(columns=['Census_PrimaryDiskTypeName']).values\n",
    "\n",
    "\n",
    "#     enc = OneHotEncoder().fit(f)\n",
    "#     encoders[c] = enc\n",
    "#     df[c] = enc.transform(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.557Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators':range(50, 150, 10),\n",
    "#     'max_depth':range(5, 16, 2),\n",
    "#     'min_samples_leaf':range(10, 50, 10),\n",
    "#     'min_samples_split':range(100, 400, 100),\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(\n",
    "    RandomForestClassifier(\n",
    "        #n_estimators=90,\n",
    "        #min_samples_split=200,\n",
    "        #min_samples_leaf=20,\n",
    "        #max_depth=15\n",
    "    ),\n",
    "    params, \n",
    "    cv=3, \n",
    "    n_jobs=-1, \n",
    "    verbose=10\n",
    ")\n",
    "cv = cv.fit(x, y)\n",
    "\n",
    "# print the best parameters and score\n",
    "cv.best_params_, cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-24T17:37:15.561Z"
    }
   },
   "outputs": [],
   "source": [
    "df.Census_InternalBatteryType.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bright]",
   "language": "python",
   "name": "conda-env-bright-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "741.42px",
    "left": "707.879px",
    "right": "20px",
    "top": "120px",
    "width": "378.788px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
