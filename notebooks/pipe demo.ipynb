{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T03:09:27.615562Z",
     "start_time": "2019-02-07T03:09:26.216226Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dankypipe import pipe\n",
    "# import os\n",
    "# import sys\n",
    "# sys.path.insert(0, os.path.abspath('..'))\n",
    "# from dankypipe import pipe as pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-01T03:20:24.690Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle('train.pickle').sort_values(by='AvSigVersion')\n",
    "test = pd.read_pickle('test.pickle').sort_values(by='AvSigVersion')\n",
    "\n",
    "train = train.rename(columns={'HasDetections':'Target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    df['Census_OSSkuName'] = [re.sub(r'[^a-zA-Z]+', '', s) if isinstance(s, str) else s for s in df.Census_OSSkuName]\n",
    "    df['Census_OSEdition'] = [re.sub(r'[^a-zA-Z]+', '', s) if isinstance(s, str) else s for s in df.Census_OSEdition]\n",
    "\n",
    "    # extract the media reduced OS versions\n",
    "    OS_Reduced_Media = [\n",
    "        'professionaln',\n",
    "        'coren',\n",
    "        'enterprisesn',\n",
    "        'enterprisen',\n",
    "        'professionalworkstationn',\n",
    "        'cloudn',\n",
    "        'educationn',\n",
    "        'professionaleducationn'\n",
    "    ]\n",
    "\n",
    "    mask = [\n",
    "        c[0] in OS_Reduced_Media or c[1] in OS_Reduced_Media \n",
    "        for c in df[['Census_OSSkuName', 'Census_OSEdition']].itertuples() \n",
    "    ]\n",
    "    df['OS_Reduced_Media'] = mask\n",
    "\n",
    "    for c in OS_Reduced_Media:\n",
    "        df.loc[df.Census_OSSkuName == c, 'Census_OSSkuName'] = c[:-1]\n",
    "        df.loc[df.Census_OSEdition == c, 'Census_OSEdition'] = c[:-1]\n",
    "\n",
    "    # replace the obvious typo\n",
    "    df.loc[\n",
    "        (df.Census_OSEdition == 'enterprises') |\n",
    "        (df.Census_OSSkuName == 'enterprises'),\n",
    "        ['Census_OSEdition', 'Census_OSSkuName']\n",
    "    ] = 'enterprise'\n",
    "\n",
    "\n",
    "    # There are only one of these in the entire dataset\n",
    "    df.loc[\n",
    "        (df.Census_OSEdition == 'professionalsinglelanguage') |\n",
    "        (df.Census_OSSkuName == 'professionalsinglelanguage'),\n",
    "        ['Census_OSEdition', 'Census_OSSkuName']\n",
    "    ] = 'professional'\n",
    "\n",
    "    df.loc[\n",
    "        (df.Census_OSEdition == 'professionalcountryspecific') |\n",
    "        (df.Census_OSSkuName == 'professionalcountryspecific'),\n",
    "        ['Census_OSEdition', 'Census_OSSkuName']\n",
    "    ] = 'professional'\n",
    "\n",
    "    df.loc[\n",
    "        (df.Census_OSEdition == 'professionalcountryspecific') |\n",
    "        (df.Census_OSSkuName == 'professionalcountryspecific'),\n",
    "        ['Census_OSEdition', 'Census_OSSkuName']\n",
    "    ] = 'professional'\n",
    "\n",
    "    # look for substring matches\n",
    "    step, subsets = 4, {}\n",
    "    for s in df.Census_OSEdition.unique():\n",
    "        s = str(s)\n",
    "        subsets[s] = {s[i:i+step] for i in range(len(s)-step+1)}\n",
    "\n",
    "    df['Census_OSEdSkuMatch'] = [\n",
    "        any([\n",
    "            x in z for x in subsets[y]\n",
    "        ]) if str(y) != 'nan' else False\n",
    "        for y, z in zip(df.Census_OSEdition, df.Census_OSSkuName)\n",
    "    ]\n",
    "    \n",
    "    osed_props = df.Census_OSEdition.value_counts(normalize=True)\n",
    "    ossku_props = df.Census_OSSkuName.value_counts(normalize=True)\n",
    "    \n",
    "    t = df[['Census_OSEdition', 'Census_OSSkuName', 'Census_OSEdSkuMatch', 'OS_Reduced_Media']]\n",
    "    for ix, row in df.iloc[\n",
    "        t.loc[[not b for b in t.duplicated()] & ~t.Census_OSEdSkuMatch].index][\n",
    "            ['Census_OSEdition', 'Census_OSSkuName', 'Census_OSEdSkuMatch']].iterrows():\n",
    "        a, b = osed_props[row.Census_OSEdition], ossku_props[row.Census_OSSkuName]\n",
    "        p = b/(a+b)\n",
    "        choice = np.random.binomial(1, p, 1)\n",
    "        \n",
    "        if choice == 1:\n",
    "            #print(p, 1, row.Census_OSSkuName)\n",
    "            df.loc[ix, 'Census_OSEdition'] = row.Census_OSSkuName\n",
    "        else:\n",
    "            #print(p, 0, row.Census_OSEdition)\n",
    "            df.loc[ix, 'Census_OSEdition'] = row.Census_OSEdition\n",
    "        \n",
    "    df.drop(columns=['Census_OSSkuName'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "cols  = ['Census_OSSkuName', 'Census_OSEdition', 'MachineIdentifier']\n",
    "train = train[cols+['Target']]\n",
    "test  = test[cols]\n",
    "\n",
    "train = transform(train)\n",
    "test  = transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Now upload these features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_idx = int(len(train)*.7)\n",
    "val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = train.rename(columns={'Census_OSEdition':'Census_OSEdition_reduced'})\n",
    "test  = test.rename(columns={'Census_OSEdition':'Census_OSEdition_reduced'})\n",
    "\n",
    "pbar = tqdm(total=len(train.columns)-2)\n",
    "\n",
    "for c in train.columns:\n",
    "    if c == 'MachineIdentifier' or c == 'Target':\n",
    "        continue\n",
    "        \n",
    "    pbar.set_description(c)\n",
    "    \n",
    "    train_ = train[['MachineIdentifier', c]].iloc[:val_idx, :]\n",
    "    val_   = train[['MachineIdentifier', c]].iloc[val_idx:, :]\n",
    "    test_  =  test[['MachineIdentifier', c]]\n",
    "    \n",
    "    try:\n",
    "        pipe.upload_feature(c, (train_, val_, test_))\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit a training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T03:09:29.975225Z",
     "start_time": "2019-02-07T03:09:29.970306Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"job_name\": \"a_small_demo\", \n",
    "    \"features\": [\"Wdft_IsGamer\", \"AvSigVersion\", \"AppVersion\", \"Census_DeviceFamily\",], \n",
    "    \"model\": {\n",
    "        \"name\": \"lgbm\", \n",
    "        \"parameters\": {\n",
    "            \"categorical_features\": [\n",
    "                \"AvSigVersion\", \"AppVersion\", \"Census_DeviceFamily\"\n",
    "            ], \n",
    "            \"kwargs\": {\n",
    "                \"num_boost_round\": 1400, \n",
    "                \"verbose_eval\": 100\n",
    "            }, \n",
    "            \"params\": {\n",
    "                \"objective\": \"binary\", \n",
    "                \"metric\": \"auc\", \n",
    "                \"num_leaves\": 10, \n",
    "                \"learning_rate\": 0.2\n",
    "            }\n",
    "        }\n",
    "    }, \n",
    "    \"task\": \"predict\", \n",
    "    \"tuning\": {\n",
    "        \"metric\": \"auc\", \n",
    "        \"search_type\": \"stage_wise\", \n",
    "        \"parameters\": {\n",
    "            \"kwargs.num_boost_round\": [1000, 1500],\n",
    "            \"params.num_leaves\": [8, 12], \n",
    "            \"params.learning_rate\": [0.1, 0.2]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T03:09:37.888641Z",
     "start_time": "2019-02-07T03:09:31.864148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project=DankDefense\n"
     ]
    }
   ],
   "source": [
    "job = pipe.Ec2Job(\n",
    "    config=config,\n",
    "    overwrite=True,\n",
    "    ssh_key_path='/home/luke/.ssh/aws_virginia1.pem',\n",
    "    instance_type='r5.xlarge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T03:45:48.300391Z",
     "start_time": "2019-02-07T03:45:41.914Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe.Ec2Job?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T03:15:09.494638Z",
     "start_time": "2019-02-07T03:09:41.028276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing EC2 instance\n",
      "establishing connection with ec2-3-94-125-239.compute-1.amazonaws.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/anaconda3/envs/dankd/lib/python3.7/site-packages/paramiko/kex_ecdh_nist.py:39: CryptographyDeprecationWarning: encode_point has been deprecated on EllipticCurvePublicNumbers and will be removed in a future version. Please use EllipticCurvePublicKey.public_bytes to obtain both compressed and uncompressed point encoding.\n",
      "  m.add_string(self.Q_C.public_numbers().encode_point())\n",
      "/home/luke/anaconda3/envs/dankd/lib/python3.7/site-packages/paramiko/kex_ecdh_nist.py:96: CryptographyDeprecationWarning: Support for unsafe construction of public numbers from encoded data will be removed in a future version. Please use EllipticCurvePublicKey.from_encoded_point\n",
      "  self.curve, Q_S_bytes\n",
      "/home/luke/anaconda3/envs/dankd/lib/python3.7/site-packages/paramiko/kex_ecdh_nist.py:111: CryptographyDeprecationWarning: encode_point has been deprecated on EllipticCurvePublicNumbers and will be removed in a future version. Please use EllipticCurvePublicKey.public_bytes to obtain both compressed and uncompressed point encoding.\n",
      "  hm.add_string(self.Q_C.public_numbers().encode_point())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb  7 03:10:20 UTC 2019:  installing python3-pip\n",
      "Thu Feb  7 03:10:54 UTC 2019:  installing awcli\n",
      "Thu Feb  7 03:10:58 UTC 2019:  installing the dank pipe\n",
      "Thu Feb 07 03:11:24 UTC 2019:  building dataset\n",
      "Thu Feb 07 03:14:57 UTC 2019:\n",
      "------------\n",
      "Model Source\n",
      "import lightgbm as lgb\n",
      "\n",
      "class Model:\n",
      "    def __init__(self, parameters):\n",
      "        self.parameters = parameters\n",
      "        self.model = None\n",
      "    def train(self, x, y):\n",
      "        print(self.parameters)\n",
      "        for c in self.parameters['categorical_features']:\n",
      "            x.loc[:, c] = x[c].astype('category')\n",
      "        lgb_train = lgb.Dataset(x, y)\n",
      "        self.model = lgb.train(self.parameters['params'], lgb_train, **self.parameters['kwargs'])\n",
      "    def predict(self, x):\n",
      "        return self.model.predict(x)\n",
      "------------end model\n",
      "no secrets file found. resorting to environment variables\n",
      "Fetching config...\n",
      "Downloading features...\n",
      "Feature set download complete\n",
      "{'categorical_features': ['AvSigVersion', 'AppVersion', 'Census_DeviceFamily'], 'kwargs': {'num_boost_round': 1400, 'verbose_eval': 100}, 'params': {'objective': 'binary', 'metric': 'auc', 'num_leaves': 10, 'learning_rate': 0.2}}\n",
      "Traceback (most recent call last):\n",
      "  File \"runner.py\", line 280, in <module>\n",
      "    main()\n",
      "  File \"runner.py\", line 276, in main\n",
      "    run_task(config)\n",
      "  File \"runner.py\", line 85, in run_task\n",
      "    predictions = predict(config, params)\n",
      "  File \"runner.py\", line 61, in predict\n",
      "    model.train(**train_full)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/dankypipe/models/lgbm.py\", line 15, in train\n",
      "    self.model = lgb.train(self.parameters['params'], lgb_train, **self.parameters['kwargs'])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py\", line 195, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py\", line 1510, in __init__\n",
      "    train_set.construct().handle,\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py\", line 987, in construct\n",
      "    categorical_feature=self.categorical_feature, params=self.params)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py\", line 720, in _lazy_init\n",
      "    label = _label_from_pandas(label)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py\", line 290, in _label_from_pandas\n",
      "    raise ValueError('DataFrame for label cannot have multiple columns')\n",
      "ValueError: DataFrame for label cannot have multiple columns\n",
      "Thu Feb  7 03:15:05 UTC 2019:  uploading logs\n",
      "Thu Feb  7 03:15:05 UTC 2019:  job complete\n"
     ]
    }
   ],
   "source": [
    "results = job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T23:17:01.075716Z",
     "start_time": "2019-02-03T23:17:01.067962Z"
    }
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T03:24:00.536955Z",
     "start_time": "2019-02-07T03:20:37.660965Z"
    }
   },
   "outputs": [],
   "source": [
    "fs = pipe.build_feature_set(['AppVersion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T03:31:23.910513Z",
     "start_time": "2019-02-07T03:31:23.891399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "             AppVersion\n",
      "6822125  4.9.10586.1106\n",
      "7285638   4.12.16299.15\n",
      "5050150  4.9.10586.1106\n",
      "165482   4.13.17134.228\n",
      "735046   4.9.10586.1106\n",
      "                        MachineIdentifier  Target\n",
      "6822125  c3c4bc04dc5f1c7245a862e52634428e       0\n",
      "7285638  d106fcb0c6482265956c05ffbaf60744       0\n",
      "5050150  90eeb2d77a5f58c0afe71de24f29bb50       0\n",
      "165482   04c1c463cbb6e2bfae34c4c66fd3242c       0\n",
      "735046   151dd3600408f025207073d09cbc6d5d       0\n",
      "\n",
      "\n",
      "test\n",
      "               AppVersion\n",
      "7255494   4.18.1807.18075\n",
      "7985649  4.16.17656.18052\n",
      "7255496   4.18.1807.18075\n",
      "8171601   4.18.1807.18075\n",
      "7812640   4.18.1807.18075\n",
      "None\n",
      "\n",
      "\n",
      "validate\n",
      "              AppVersion\n",
      "7252423     4.13.17134.1\n",
      "6804872   4.13.17134.320\n",
      "6882538   4.13.17134.228\n",
      "6856130      4.18.1809.2\n",
      "2544324  4.18.1807.18075\n",
      "                        MachineIdentifier\n",
      "7252423  ec6910b4d9e0baae203e9819227659ec\n",
      "6804872  ddd66992da9cbb12db76d9d874fedf8b\n",
      "6882538  e05db268c5f1e48e5fa63de1f39f02d7\n",
      "6856130  df81a38177efaac6b95df42ddef504e6\n",
      "2544324  52eb832b198099b467d39481a77afcef\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in fs.items():\n",
    "    print(k)\n",
    "    print(v['x'].head())\n",
    "    print(v['y'].head() if v['y'] is not None else None)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T03:18:41.140251Z",
     "start_time": "2019-02-07T03:17:03.180121Z"
    }
   },
   "outputs": [],
   "source": [
    "target = pipe.download_feature('Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T03:19:04.814697Z",
     "start_time": "2019-02-07T03:19:04.794769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "                        MachineIdentifier  Target\n",
      "6822125  c3c4bc04dc5f1c7245a862e52634428e       0\n",
      "7285638  d106fcb0c6482265956c05ffbaf60744       0\n",
      "5050150  90eeb2d77a5f58c0afe71de24f29bb50       0\n",
      "165482   04c1c463cbb6e2bfae34c4c66fd3242c       0\n",
      "735046   151dd3600408f025207073d09cbc6d5d       0\n",
      "test\n",
      "                        MachineIdentifier  Target\n",
      "7255494  d02af699e3a7618914f8c538baefeb68       0\n",
      "7985649  e5213bf0841076b663600920aa060c8f       1\n",
      "7255496  d02af933ab7c06b5b7a74a6c5cd37094       0\n",
      "8171601  ea787571d0e36842d9866ebd2cc878f5       0\n",
      "7812640  e029fef2d6199e20e95c030d0f06ccd4       1\n",
      "validate\n",
      "                        MachineIdentifier\n",
      "7252423  ec6910b4d9e0baae203e9819227659ec\n",
      "6804872  ddd66992da9cbb12db76d9d874fedf8b\n",
      "6882538  e05db268c5f1e48e5fa63de1f39f02d7\n",
      "6856130  df81a38177efaac6b95df42ddef504e6\n",
      "2544324  52eb832b198099b467d39481a77afcef\n"
     ]
    }
   ],
   "source": [
    "for k, v in target.items():\n",
    "    print(k)\n",
    "    print(v.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T03:16:12.901761Z",
     "start_time": "2019-02-07T03:16:12.203235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TerminatingInstances': [{'CurrentState': {'Code': 32,\n",
       "    'Name': 'shutting-down'},\n",
       "   'InstanceId': 'i-06da7e73adf66213a',\n",
       "   'PreviousState': {'Code': 16, 'Name': 'running'}}],\n",
       " 'ResponseMetadata': {'RequestId': '553cb4cb-3f68-43f8-8739-1361a66835a7',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'text/xml;charset=UTF-8',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'vary': 'Accept-Encoding',\n",
       "   'date': 'Thu, 07 Feb 2019 03:16:13 GMT',\n",
       "   'server': 'AmazonEC2'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.terminate_instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T22:28:38.610551Z",
     "start_time": "2019-02-03T22:28:38.608409Z"
    }
   },
   "outputs": [],
   "source": [
    "del job, results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dankd]",
   "language": "python",
   "name": "conda-env-dankd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
